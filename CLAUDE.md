# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## 0) Identity & Mission
You are the **Agentic Morning Digest** dev assistant. Goal: ship a one-day MVP that generates a **personalized daily digest** mixing ‚Äúneed-to-know‚Äù (AI/news/history/politics) with ‚Äúnice-to-know‚Äù (quotes, trivia, what-ifs). Output lives in a **Streamlit** app with a visible ‚ÄúAgent Thinking Log.‚Äù

**Non-goals:** building auth, multi-user infra, production DB, fancy styling, or real-time crawling beyond the three sources.

## 1) Commands

### Development
- **Environment:** Use the `news_push` conda/virtual environment
- **Install dependencies:** `pip install -r requirements.txt`
- **Run the application:** `cd app && streamlit run app.py`
- **Environment setup:** Ensure `OPENAI_API_KEY` is set in environment (for future LLM integration)

### Demo Constraints (3-minute screen recording)
- Must show: pick preferences ‚Üí show "Agent plan" ‚Üí interleaved sections (need/nice) ‚Üí regenerate.
- Fast and reliable: prefer **cached/mocked** data if scraping/LLM is slow.

## 2) Tech Stack (MVP)
- **Frontend:** Streamlit
- **LLM:** GPT (for summaries/reframes); keep calls minimal and deterministic (temperature low)
- **Agent Framework:** LangGraph for AI agent orchestration (see tutorials in `/tutorials/langgraph-docs/`)
- **Retrieval:** Playwright (JS sites) + BeautifulSoup (parse). Provide **mock switch** + **cache**
- **Storage:** In-memory / JSON file for prefs + cached content

### LangGraph Resources
Reference documentation in `/tutorials/langgraph-docs/`:
- **Agent Overview:** `/agents/overview.md` - Core agent concepts and patterns
- **Prebuilt Components:** `/agents/prebuilt.md` - Ready-to-use agent building blocks  
- **Multi-Agent Systems:** `/agents/multi-agent.md` - Coordinating multiple agents
- **Memory Integration:** How-to guides for session and persistent memory
- **Human-in-the-loop:** Patterns for interactive agent workflows

## 3) Sources (start with 3)
- **Hacker News** (front page) ‚Üí ‚ÄúQuick Hits‚Äù tech/AI headlines  
- **Wikipedia ‚Äì Selected anniversaries / On This Day** ‚Üí ‚ÄúDid You Know‚Äù history bits  
- **quotes.toscrape.com** ‚Üí ‚ÄúQuote / Fun Spark‚Äù  
Add RSS/API later only if time allows.

## 4) Architecture & Code Structure

### Core Architecture
The application follows a modular pipeline architecture:
1. **Preferences Collection** ‚Üí **Planning** ‚Üí **Content Retrieval** ‚Üí **Content Processing** ‚Üí **Presentation**
2. **Agent Thinking Log** runs parallel to track all decisions and actions
3. **Fallback Strategy** ensures resilience: Live Data ‚Üí Cache ‚Üí Static Samples

### Module Responsibilities
- **app.py**: Streamlit UI + wiring + Agent Log display
- **manager.py**: Plans sections & order (need/nice interleave) + decision logging  
- **retriever.py**: Scraping (HN/Wiki/Quotes) + cache + USE_LIVE flag + fallback logic
- **editors.py**: NeedToKnow / NiceToKnow content transformers + LLM calls
- **presenter.py**: Pure rendering helpers (no business logic)
- **prefs.py**: Load/save user preferences (JSON / session_state)
- **data/static_samples.json**: Fallback content for demo resilience

### Data Flow
```
User Prefs ‚Üí Manager.plan_sections() ‚Üí Retriever.fetch_*() ‚Üí Editors.transform() ‚Üí Presenter.render()
                    ‚Üì
              Agent Log (tracks all decisions)
```

## 5) Section Contract
Each section is a dict:
{
  "id": "quick_hits" | "deep_dive" | "did_you_know" | "fun_spark" | "quote",
  "title": "üìå Quick Hits You Should Know",
  "kind": "need" | "nice",
  "items": [{"text": "...", "url": optional}]
}

## 6) Agentic Workflow (what to implement)
1. **Collect prefs** (topics, mood, time budget) in sidebar.  
2. **Manager.plan_sections(prefs)**  
   - Rules: if topics include AI/History/Politics ‚Üí select `quick_hits`, `deep_dive` (need)  
   - Always include one `nice` block (`quote` or `fun_spark`)  
   - Interleave pattern: **need ‚Üí nice ‚Üí need** (max 3‚Äì4 sections)  
   - Log decisions to ‚ÄúAgent Thinking Log‚Äù.
3. **Retriever.fetch_*()**  
   - Try cached; if `USE_LIVE=True`, scrape via Playwright; else use `data/static_samples.json`.  
   - Parse with BeautifulSoup; return minimal clean fields.  
   - On failure, **fallback** to cache/static and log reason.
4. **Editors**  
   - `need_to_know(sec, data)`: one-sentence bullets; optional 1-paragraph ‚ÄúDeep Dive‚Äù (LLM-summarize a single item).  
   - `nice_to_know(sec, data)`: quote or playful what-if; deterministic prompt; no external calls if possible.
5. **Presenter.render(sections)**  
   - Pure formatting; add badges for need/nice; collapsible expanders.  
6. **Observability**  
   - Every step appends a concise log line: `[Planner] chose X`, `[Retriever] cache hit for HN`, etc.

## 7) Coding Standards & Safety
- Python 3.11+, type hints, small pure functions, docstrings, `black` format.
- **No secrets in code**. Expect `OPENAI_API_KEY` via env.  
- Use `@st.cache_data(ttl=600)` for network calls.  
- Timebox scraping to 3s/site; then fallback.  
- LLM: `temperature=0.2`, bounded output via explicit bullet/char limits.

## 8) Prompts (edit as needed)
**Planner prompt (system):**  
‚ÄúYou plan a 3‚Äì4 section morning digest mixing *need-to-know* (news/deep-dive) and *nice-to-know* (quote/what-if). Given {topics, mood, time_budget}, choose section IDs from: [`quick_hits`, `deep_dive`, `did_you_know`, `quote`, `fun_spark`]. Return JSON: `{order:[...], rationale:[...]}`. Prefer pattern need‚Üínice‚Üíneed.‚Äù

**Need summary prompt (user):**  
‚ÄúSummarize this headline+snippet for a daily digest. 1 sentence, ‚â§25 words, neutral, add why it matters. Input:\n{headline}\n{snippet}‚Äù

**Fun spark prompt (user):**  
‚ÄúWrite one playful ‚Äòwhat-if‚Äô (‚â§25 words) connecting {topic} to history/politics. Keep it tasteful, no speculation about real people‚Äôs private lives.‚Äù

## 9) Implementation Priority
**Build in this order to maintain demo readiness:**
1. **MVP Foundation**: `app.py` skeleton with sidebar prefs, Generate button, Agent Log expander
2. **Static Data**: Create `data/static_samples.json` with sample content from all sources
3. **Planning Logic**: Implement `manager.plan_sections()` with decision rules and logging
4. **Presentation Layer**: Build `presenter.render()` with markdown cards and collapsible expanders
5. **Content Pipeline**: Implement `retriever.py` cache + mock + optional live scraping
6. **LLM Integration**: Add minimal LLM calls for "Deep Dive" summaries only

**Critical Path**: Steps 1-4 create a working demo. Steps 5-6 add real functionality.

## 10) Failure & Fallback Policy
If any scraper/LLM step fails or exceeds latency budget:  
- Log: reason + switch (‚Äúfallback to cache‚Äù).  
- Keep UI responsive; never crash app.  
- Regenerate only the failed section, not the whole page.
